
\documentclass[10pt,handout]{beamer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathpazo}
\usepackage{graphicx}
\usepackage{color}
\usepackage{appendix}
\usepackage{supertabular}
\usepackage{booktabs,tabularx}
\usepackage[comma]{natbib}
\usepackage{beamerthemesplit}
\usepackage{mathpazo}
\usepackage[T1]{fontenc}
\usepackage[orientation=landscape,size=custom,width=16,height=9,scale=0.5,debug]{beamerposter}
\usepackage{color}
\usepackage{bm}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="2">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Tuesday, August 24, 2010 17:53:05}
%TCIDATA{LastRevised=Friday, February 07, 2014 19:06:33}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Other Documents\SW\Slides - Beamer">}
%TCIDATA{Language=American English}
%TCIDATA{CSTFile=beamer.cst}

\usefonttheme[onlymath]{serif}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}
\useinnertheme{rounded}
\setbeamertemplate{navigation symbols}{}
\definecolor{title}{RGB}{0,0,90}
\definecolor{note}{RGB}{49,79,179}
\setbeamercolor{titlelike}{fg=title!95,bg=white} 
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamerfont{frametitle}{series=\bfseries}
\setbeamerfont{frametitle}{size=\large}
\defbeamertemplate*{footline}{shadow theme}{\leavevmode\hbox{
    \begin{beamercolorbox}[wd=1.01\paperwidth, ht=2.5ex, dp=1.125ex, leftskip=.3cm plus1fil,rightskip=0.3cm]
    {author in head/foot}\insertshorttitle \insertsection \hspace{.3cm} \hfill \insertframenumber    \end{beamercolorbox}
}}
\defbeamertemplate*{headline}{shadow theme}{\leavevmode\hbox{
}}
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamertemplate{itemize items}[triangle] 
\setbeamertemplate{itemize subitem}[circle]
\setbeamertemplate{enumerate items}[default]
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\input{tcilatex}
\graphicspath{{./graphics/}}
\def\newblock{\hskip .11em plus .33em minus .07em}
\begin{document}

\title[VAR models]{\textbf{A Primer on Vector Autoregressions}}
\author{Ambrogio Cesa-Bianchi}
\date{}
\maketitle

\section{ -- VAR\ Representation}

\begin{frame}
\begin{equation*}
\text{\textbf{[DISCLAIMER]}}
\end{equation*}

These notes are meant to provide intuition on the basic mechanisms of
VARs\bigskip \pause

As such, most of the material covered here is treated in a very informal
way\bigskip \pause

If you crave a formal treatment of these topics, you should stop here and
buy a copy of Hamilton's \textquotedblleft Time Series
Analysis\textquotedblright
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{VARs \& Macro-econometricians' job}}

\begin{itemize}
\item According to a well-known paper by Stock \&\ Watson (2001, JEP)
macroeconometricians (would like to) do four things\smallskip

\begin{enumerate}
\item Describe and summarize macroeconomic time series\smallskip \pause

\item Make forecasts\smallskip \pause

\item Recover the true structure of the macroeconomy from the data\smallskip 
\pause

\item Advise macroeconomic policymakers\medskip \pause
\end{enumerate}

\item Vector autoregressive models are a statistical tool to address these
tasks
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What can we do with vector autoregressive models?}}

\begin{itemize}
\item 3 variables:\ real GDP\ growth ($\Delta y$), inflation ($\pi $) and
the policy rate ($i$)\medskip \pause

\item A VAR\ can help us answering the following questions\smallskip

\begin{enumerate}
\item What is the dynamic behaviour of these variables? How do these
variables interact?\smallskip \pause

\item What is the profile of GDP conditional on a specific future path for
the policy rate? \smallskip \pause

\item What is the effect of a monetary policy shock on GDP and
inflation?\smallskip \pause

\item What has been the contribution of monetary policy shocks to the
behaviour of GDP\ over time?
\end{enumerate}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What is a Vector Autoregression (VAR)?}}

\begin{itemize}
\item Given, for example, a $(3\times 1)$ vector of time series $\mathbf{x}%
_{t}$ where%
\begin{equation*}
\mathbf{x}_{t}=\left[ 
\begin{array}{cccc}
\Delta y_{1} & \Delta y_{2} & ... & \Delta y_{T} \\ 
\pi _{1} & \pi _{2} & ... & \pi _{T} \\ 
r_{1} & r_{2} & ... & r_{T}%
\end{array}%
\right]
\end{equation*}%
\pause

\item A {{\color{red} stationary structural}} VAR of order $1$ is%
\begin{equation*}
\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+\mathbf{\varepsilon }_{t}\ \ \ \ \ \text{%
for }t=1,...,T
\end{equation*}

\begin{itemize}
\item $\mathbf{A}$ and $\mathbf{B}$ are $(3\times 3)$ matrices of
coefficients

\item $\mathbf{\varepsilon }_{t}$ is an $(3\times 1)$ vector of unobservable
zero mean white noise processes
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Three different ways of writing the same thing}}

\begin{itemize}
\item There are different ways to represent the VAR(1)%
\begin{equation*}
\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+\mathbf{\varepsilon }_{t}
\end{equation*}%
\pause

\item For example, we can also write it:

\begin{itemize}
\item In matrix form%
\begin{equation*}
\left[ 
\begin{array}{ccc}
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\ 
{a}_{{31}} & {a}_{{31}} & a_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t} \\ 
\pi _{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
b_{11} & b_{12} & b_{13} \\ 
b_{21} & b_{22} & b_{23} \\ 
b_{31} & b_{32} & b_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t-1} \\ 
\pi _{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+%
\begin{bmatrix}
\varepsilon _{\Delta yt} \\ 
\varepsilon _{\pi t} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
\end{equation*}%
\pause

\item As a system of linear equation%
\begin{equation*}
\left\{ 
\begin{array}{l}
a_{11}\Delta y_{t}+a_{12}\pi _{t}+a_{13}r_{t}=b_{11}\Delta y_{t-1}+b_{12}\pi
_{t-1}+b_{13}r_{t-1}+\varepsilon _{\Delta yt}\smallskip \\ 
a_{21}\Delta y_{t}+a_{22}\pi _{t}+a_{13}r_{t}=b_{21}\Delta y_{t-1}+b_{22}\pi
_{t-1}+b_{23}r_{t-1}+\varepsilon _{\pi t}\smallskip \\ 
a_{31}\Delta y_{t}+a_{32}\pi _{t}+a_{33}r_{t}=b_{31}\Delta y_{t-1}+b_{32}\pi
_{t-1}+b_{33}r_{t-1}+\varepsilon _{rt}%
\end{array}%
\right.
\end{equation*}
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{The structural innovations}}

\begin{itemize}
\item We defined $\mathbf{\varepsilon }_{t}$ as a \textquotedblleft vector
of unobservable zero mean white noise processes\textquotedblright . What
does it mean?\medskip \pause

\item This simply means that they are serially uncorrelated and independent
of each other\medskip \pause

\item In other words 
\begin{equation*}
\mathbf{\varepsilon }_{t}=(\varepsilon _{\Delta yt}^{\prime },\varepsilon
_{\pi t}^{\prime },\varepsilon _{rt}^{\prime })^{\prime }\sim \mathcal{N}(0,%
\mathbf{I})
\end{equation*}%
or%
\begin{equation*}
\mathsf{VCV(}\mathbf{\varepsilon }_{t})=\left[ 
\begin{array}{ccc}
1 & 0 & 0 \\ 
- & 1 & 0 \\ 
- & - & 1%
\end{array}%
\right] \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \mathsf{CORR}(\mathbf{\varepsilon }%
_{t})=\left[ 
\begin{array}{ccc}
1 & 0 & 0 \\ 
- & 1 & 0 \\ 
- & - & 1%
\end{array}%
\right]
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!80,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!80,bg=note!80}
%\setbeamercolor{note in head/foot}{fg=note!80,bg=note!80}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!99}}
%\everydisplay\expandafter{\the\everydisplay \color{note!99}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!80,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!80,bg=note!80}
\setbeamercolor{note in head/foot}{fg=note!80,bg=note!80}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!99}}
\everydisplay\expandafter{\the\everydisplay \color{note!99}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {What is a
variance-covariance matrix?} }}

\begin{itemize}
\item The formula for the variance of a univariate time series $%
x=[x_{1},x_{2},...,x_{T}]$ is%
\begin{equation*}
\mathsf{VAR}=\sum_{t=0}^{T}\frac{\left( x_{t}-\bar{x}\right) ^{2}}{N}%
=\sum_{t=0}^{T}\frac{\left( x_{t}-\bar{x}\right) \left( x_{t}-\bar{x}\right) 
}{N}
\end{equation*}%
\pause

\item If we have a bivariate time series 
\begin{equation*}
\mathbf{x}_{t}=\left[ 
\begin{array}{cccc}
x_{1} & x_{2} & ... & x_{T} \\ 
y_{1} & y_{2} & ... & y_{T}%
\end{array}%
\right] 
\end{equation*}%
\pause the formula becomes%
\begin{equation*}
\small\mathsf{VCV}=\left[ 
\begin{array}{cc}
\sum_{t=0}^{T}\frac{\left( x_{t}-\bar{x}\right) \left( x_{t}-\bar{x}\right) 
}{N} & \sum_{t=0}^{T}\frac{\left( x_{t}-\bar{x}\right) \left( y_{t}-\bar{y}%
\right) }{N} \\ 
\sum_{t=0}^{T}\frac{\left( y_{t}-\bar{y}\right) \left( x_{t}-\bar{x}\right) 
}{N} & \sum_{t=0}^{T}\frac{\left( y_{t}-\bar{y}\right) \left( y_{t}-\bar{y}%
\right) }{N}%
\end{array}%
\right] =\left[ 
\begin{array}{cc}
\mathsf{VAR}(x) & \mathsf{COV}(x,y) \\ 
\mathsf{COV}(x,y) & \mathsf{VAR}(y)%
\end{array}%
\right] 
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
{\textbf{The general form of the stationary structural VAR(p) model}}

\begin{itemize}
\item The basic VAR(1) model may be too poor to sufficiently summarize the
main characteristics of the data\medskip \pause

\begin{itemize}
\item Deterministic terms (such as time trend or seasonal dummy variables)

\item Exogenous variables (such as the price of oil)\medskip \pause
\end{itemize}

\item The general form of the VAR(p) model with deterministic terms ($%
\mathbf{Z}_{t}$) and exogenous variables ($\mathbf{W}_{t}$) is given by%
\begin{equation*}
\mathbf{Ax}_{t}=\mathbf{B}_{1}\mathbf{x}_{t-1}+\mathbf{B}_{2}\mathbf{x}%
_{t-2}+...+\mathbf{B}_{p}\mathbf{x}_{t-p}+\boldsymbol{\Lambda }\mathbf{Z}%
_{t}+\boldsymbol{\Psi }\mathbf{W}_{t}+\mathbf{\varepsilon }_{t}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{Why is it called structural VAR?}}

\begin{itemize}
\item The equations of a structural VAR\ define the {{\color{red} true
structure of the economy}}\medskip \pause

\item The fact that $\mathbf{\varepsilon }_{t}=(\varepsilon _{\Delta
yt}^{\prime },\varepsilon _{\pi t}^{\prime },\varepsilon _{rt}^{\prime
})^{\prime }\sim \mathcal{N}(0,\mathbf{I})$ implies that we can interpret $%
\mathbf{\varepsilon }_{t}$ as structural shocks \medskip \pause

\item For example we could interpret

\begin{itemize}
\item $\varepsilon _{\Delta yt}$ as an {aggregate shock}

\item $\varepsilon _{\pi t}$ as a {cost-push shock}

\item $\varepsilon _{rt}$ as a {monetary policy shock}
\end{itemize}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{Why is it called stationary VAR?}}

\begin{itemize}
\item One of the main assumptions of standard VARs is stationarity of the
data \medskip \pause

\item A stochastic process is said {{\color{red} covariance stationary}} if
its first and second moments, $\mathsf{E}\left( x\right) $ and $\mathsf{VCV}%
\left( x\right) $ respectively, exist and are constant over time\pause
\begin{figure}[tbh]
\centering\includegraphics[width=.25\textwidth]{GDP.pdf} %
\includegraphics[width=.25\textwidth]{GDP_Detrend.pdf} %
\includegraphics[width=.25\textwidth]{GDP_QoQ.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{Structural VARs potentially answers many interesting questions}}

\begin{itemize}
\item For example in our VAR(1)%
\begin{equation*}
\left[ 
\begin{array}{ccc}
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\ 
{%
\begin{array}{c}
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{a}_{{31}}%
\end{array}%
} & {%
\begin{array}{c}
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
a_{32}%
\end{array}%
} & a_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t} \\ 
\pi _{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
b_{11} & b_{12} & b_{13} \\ 
b_{21} & b_{22} & b_{23} \\ 
b_{31} & b_{32} & b_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t-1} \\ 
\pi _{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+%
\begin{bmatrix}
\varepsilon _{\Delta yt} \\ 
\varepsilon _{\pi t} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
\end{equation*}%
\pause

\begin{itemize}
\item $a_{31}$ is the impact multiplier of monetary policy shocks on
GDP\smallskip 

\item $a_{32}$ is the impact multiplier of monetary policy shocks on
inflation\smallskip 

\item If we simulate the model, we can evaluate the time profile of a
monetary policy shock on GDP\smallskip 

\item We can add additional variables (and equations) and simulate other
shocks: credit supply, oil price, QE,...
\end{itemize}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{However... the estimation of structural VARs is problematic}}

\begin{itemize}
\item The equations of $\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+\mathbf{%
\varepsilon }_{t}$ cannot be estimated with OLS\ because they violate one
important assumption $\Longrightarrow $\ {{\color{red} the regressor cannot
be correlated with the error term}}\medskip \pause

\begin{itemize}
\item To see that, take the GDP equation%
\begin{equation*}
a_{11}\Delta y_{t}+a_{12}\pi _{t}+a_{13}r_{t}=b_{11}\Delta y_{t-1}+b_{12}\pi
_{t-1}+b_{13}r_{t-1}+\varepsilon _{\Delta yt}
\end{equation*}%
and compute $\mathsf{COV}[\pi _{t},\varepsilon _{yt}]$\medskip \pause
\end{itemize}

\item OLS\ estimation of $\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+\mathbf{%
\varepsilon }_{t}$ would produce inconsistent estimates of the parameters,
impulse responses, etc
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{How to solve this problem?}}

\begin{itemize}
\item In the GDP equation%
\begin{equation*}
a_{11}\Delta y_{t}+a_{12}\pi _{t}+a_{13}r_{t}=b_{11}\Delta y_{t-1}+b_{12}\pi
_{t-1}+b_{13}r_{t-1}+\varepsilon _{\Delta yt}
\end{equation*}%
the terms $a_{12}\pi _{t}$ and $a_{13}r_{t}$ are the ones generating
problems for OLS\ estimation\medskip \pause

\item This endogeneity problem disappears if we remove the contemporaneous
dependence of $\Delta y_{t}$ on the other endogenous variables\medskip 
\pause

\item More in general the $\mathbf{A}$\ matrix is problematic (since it
includes all the contemporaneous relation among the endogenous variables)
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item We can solve this problem by simply pre-multiplying the VAR\ by $%
\mathbf{A}^{-1}$ 
\begin{equation*}
\begin{array}{c}
\mathbf{A}^{-1}\mathbf{Ax}_{t}=\mathbf{A}^{-1}\mathbf{Bx}_{t-1}+\mathbf{A}%
^{-1}\mathbf{\varepsilon }_{t} \\ 
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{t} \\ 
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+\mathbf{u}_{t}%
\end{array}%
\end{equation*}%
\pause

\item That is, we moved the {{\color{red} contemporaneous dependence}} of
the endogenous variables (which is given by $\mathbf{A}$) into the
\textquotedblleft modified\textquotedblright\ error terms $\mathbf{u}_{t}$%
\medskip \pause

\item This implies that now $\mathsf{CORR}(\mathbf{u}_{t})\neq \mathbf{I}$
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {The inverse of a
matrix } }}

\begin{itemize}
\item The inverse of a $2\times 2$ matrix 
\begin{equation*}
\mathbf{X}=%
\begin{bmatrix}
a & b \\ 
c & d%
\end{bmatrix}%
\text{\ \ \ \ \ \ }\mathbf{X}^{-1}=\frac{1}{ad-bc}%
\begin{bmatrix}
d & -b \\ 
-c & a%
\end{bmatrix}%
\end{equation*}%
\pause

\item This implies that $\mathbf{u}_{t}=\mathbf{A}^{-1}\mathbf{\varepsilon }%
_{t}$ can be computed as%
\begin{equation*}
\begin{array}{l}
u_{1t}=\frac{a_{22}\varepsilon _{1t}-a_{21}\varepsilon _{2t}}{\Delta }%
\medskip \\ 
u_{2t}=\frac{-a_{21}\varepsilon _{1t}+a_{11}\varepsilon _{2t}}{\Delta }%
\end{array}%
\end{equation*}%
where $\Delta =a_{11}a_{22}-a_{12}a_{21}$
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
{\textbf{The reduced-form VAR}}

\begin{itemize}
\item This alternative formulation of the VAR%
\begin{equation*}
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+\mathbf{u}_{t}
\end{equation*}%
is called the \emph{reduced-form} representation\medskip \pause

\item In matrix form%
\begin{equation*}
\begin{bmatrix}
\Delta y_{t} \\ 
\pi _{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
f_{11} & f_{12} & f_{13} \\ 
f_{21} & f_{22} & f_{23} \\ 
f_{31} & f_{32} & f_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t-1} \\ 
\pi _{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+%
\begin{bmatrix}
u_{\Delta yt} \\ 
u_{\pi t} \\ 
u_{it}%
\end{bmatrix}%
\end{equation*}%
where%
\begin{equation*}
\mathbf{u}_{t}\sim \mathcal{N}(0,\Sigma _{\mathbf{u}})\ \ \ \ \ \text{and}\
\ \ \ \ \mathsf{CORR}(\mathbf{u}_{t})=\left[ 
\begin{array}{ccc}
1 & \rho _{12} & \rho _{13} \\ 
- & 1 & \rho _{23} \\ 
- & - & 1%
\end{array}%
\right]
\end{equation*}
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- VAR\ Estimation}

\begin{frame}
%TCIMACRO{\TeXButton{section}{\color{title} \centering \Large}}%
%BeginExpansion
\color{title} \centering \Large%
%EndExpansion
\textbf{VAR\ Estimation}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{We can now estimate the VAR with some real data}}

\begin{itemize}
\item UK\ quarterly data from 1985.I to 2013.III\medskip 

\item VAR(1) with a constant $\mathbf{x}_{t}=\mathbf{c}+\mathbf{Fx}_{t-1}+%
\mathbf{u}_{t}$\bigskip 
\begin{figure}[h]
\centering
\includegraphics[width=.30\textwidth]{X1.pdf} \includegraphics[width=.30%
\textwidth]{X2.pdf} \includegraphics[width=.30\textwidth]{X3.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{OLS\ estimation -- Typical VAR\ output}}

\begin{itemize}
\item Matrix of coefficients $\mathbf{F}^{\prime }$%
\begin{table}[tbph]
{\footnotesize \centering 
\begin{tabular}{lrrr}
\addlinespace \toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule c & 1.14 & 1.19 & -0.11 \\ 
Real GDP(-1) & 0.61 & -0.07 & 0.06 \\ 
GDP Deflator(-1) & -0.09 & 0.02 & 0.03 \\ 
Policy Rate(-1) & 0.01 & 0.30 & 0.96 \\ 
\bottomrule &  &  & 
\end{tabular}%
}
\end{table}

\item Correlation between reduced-form residuals 
\begin{table}[tbph]
{\footnotesize \centering 
\begin{tabular}{lrrr}
\addlinespace \toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule Real GDP & 1.000 & -0.178 & 0.373 \\ 
GDP Deflator & -- & 1.000 & 0.137 \\ 
Policy Rate & -- & -- & 1.000 \\ 
\bottomrule &  &  & 
\end{tabular}%
}
\end{table}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Debunking the typical VAR\ output}}

\begin{itemize}
\item The constant {{\color{red} is not}} the mean nor the long-run
equilibrium of a variable\pause

\begin{itemize}
\item In our example, the mean of the policy rate is not negative 
\begin{table}[tbph]
{\footnotesize \centering%
\begin{tabular}{lrrr}
\addlinespace\toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule c & 1.14 & 1.19 & -0.11%
\end{tabular}%
}
\end{table}
\medskip \pause
\end{itemize}

\item The correlation of the residuals reflects the {{\color{red}
contemporaneous} relation between our variables}\pause

\begin{itemize}
\item In our example GDP growth and inflation are contemporaneously
negatively correlated 
\begin{table}[tbph]
{\footnotesize \centering%
\begin{tabular}{lrrr}
\addlinespace\toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule Real GDP & 1.000 & -0.178 & 0.373%
\end{tabular}%
}
\end{table}
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Model checking \& tuning}}

\begin{itemize}
\item We do not cover this in detail but before interpreting the VAR results
you should check a number of assumptions\medskip \pause

\item Loosely speaking we need to check that the {{\color{red} reduced-form
residuals}} are

\begin{itemize}
\item Normally distributed

\item Not autocorrelated

\item Not heteroskedastic (i.e., have constant variance)\medskip \pause
\end{itemize}

\item ... and that the VAR is stationary (we'll see in a second what it
means)
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Model checking: why the residuals?}}

\begin{itemize}
\item The VAR believes that%
\begin{equation*}
\mathbf{x}{\small \sim \mathcal{N}(\mathbf{\mu },\mathbf{\sigma })\ \ \
\Longrightarrow \ \ \ }\left\{ {\small 
\begin{array}{lll}
\Delta y & \sim & \mathcal{N}(\mu ^{\Delta y},\sigma ^{\Delta y}) \\ 
\pi & \sim & \mathcal{N}(\mu ^{\pi },\sigma ^{\pi }) \\ 
i & \sim & \mathcal{N}(\mu ^{i},\sigma ^{i})%
\end{array}%
}\right.
\end{equation*}

\item If the data that we feed into the VAR\ has not these features, the
residuals will inherit them\pause

\item Note that

\begin{itemize}
\item Mean ($\mathbf{\mu }$) and variance\ (${\small \mathbf{\sigma }}$) are
constant $\Longrightarrow $ the data have to be stationary!\smallskip 
\pause

\item The mean ($\mathbf{\mu }$) and variance\ (${\small \mathbf{\sigma }}$)
are not known a priori \smallskip \pause

\item At each point in time $\mathbf{x}_{t}$ does not generally coincide
with $\mathbf{\mu }$ because of (i) shocks hitting at $t$ and (ii) shocks
that hit in the past and that are slowly dying out \smallskip \pause

\item The average of $\mathbf{x}_{t}$ over a given sample does not
necessarily coincide with $\mathbf{\mu }$
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Can we recover the mean of our endogenous variables?}}

\begin{itemize}
\item Yes. It is given by $\mathbf{\mu =}\mathsf{E}[\mathbf{x}_{t}]$\medskip %
\pause%
\begin{equation*}
{\small 
\begin{array}{lll}
\mathsf{E}[\mathbf{x}_{t}] & = & \mathsf{E}[\mathbf{c}+\mathbf{Fx}_{t-1}+%
\mathbf{u}_{t}]=\smallskip \\ 
& = & \mathsf{E}[\mathbf{c+F(c+Fx}_{t-2}\mathbf{+u}_{t-1}\mathbf{)+u}_{t}%
\mathbf{]=E[c+Fc+F}^{2}\mathbf{x}_{t-2}\mathbf{+Fu}_{t-1}\mathbf{+u}_{t}%
\mathbf{]=}\smallskip \\ 
& = & \mathsf{E}[\mathbf{c+Fc+F}^{2}\mathbf{c+...+F}^{t-2}\mathbf{c+F}^{t-1}%
\mathbf{x}_{1}\mathbf{+F}^{t-2}\mathbf{u}_{2}\mathbf{+...+F}^{2}\mathbf{u}%
_{t-2}\mathbf{+Fu}_{t-1}\mathbf{+u}_{t}]=\smallskip \\ 
& = & ...\ =\smallskip \\ 
& = & \mathsf{E}\left[ \sum\limits_{j=0}^{t-2}\mathbf{F}^{j}\mathbf{c}+%
\mathbf{F}^{t-1}\mathbf{x}_{1}+\sum\limits_{j=0}^{t-2}\mathbf{F}^{j}\mathbf{u%
}_{t-j}\right]%
\end{array}%
}
\end{equation*}%
\pause

\item If VAR\ is stationary, from the last expression we get%
\begin{equation*}
\mathsf{E}[\mathbf{x}_{t}]=\left( \mathbf{I}-\mathbf{F}\right) ^{-1}\mathbf{c%
}=\mathbf{\mu }
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {Geometric series } }}

\begin{itemize}
\item Consider the following sum $\sum\limits_{j=0}^{T}\mathbf{Y}^{j}$%
\medskip \pause

\item When $T\rightarrow \infty $ we have: 
\begin{equation*}
\mathbf{(1+Y}+\mathbf{Y}^{2}+\mathbf{...}+\mathbf{Y}^{\infty }\mathbf{)=}%
\left( \mathbf{I}-\mathbf{Y}\right) ^{-1}
\end{equation*}%
if and only if:\pause

\begin{itemize}
\item $\left\vert eig(\mathbf{Y)}\right\vert <1$ when $\mathbf{Y}$ is a
matrix\pause

\item $\mathbf{Y}<1$ when $\mathbf{Y}$ is a number\medskip \pause
\end{itemize}

\item Therefore, for $T$ large enough we have 
\begin{equation*}
\small\mathsf{E}\left[ \sum\limits_{j=0}^{t-2}\mathbf{F}^{j}\mathbf{c}+%
\mathbf{F}^{t-1}\mathbf{x}_{0}+\sum\limits_{j=0}^{t-2}\mathbf{F}^{j}\mathbf{u%
}_{t-j}\right] =\mathsf{E}\left[ \left( \mathbf{I}-\mathbf{F}\right) ^{-1}%
\mathbf{c}\right] +\underset{\approx 0}{\underbrace{\mathbf{F}^{t-1}\mathbf{x%
}_{1}}}+\underset{\approx 0}{\underbrace{\mathsf{E}\left[ \sum%
\limits_{j=0}^{t-2}\mathbf{F}^{j}\mathbf{u}_{t-j}\right] }}
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
{\textbf{Stationary VAR, stationary data}}

\begin{itemize}
\item A VAR\ is stationary (or stable) when 
\begin{equation*}
\left\vert eig(\mathbf{F)}\right\vert <1
\end{equation*}

\item In that case, the VAR thinks that $\mathbf{(I-\mathbf{F})}^{-1}\mathbf{%
c}$ is the {{\color{red} unconditional mean}} of the stochastic processes
governing our variables\medskip 

\item VAR models stationary data

\begin{itemize}
\item GDP level clearly does not have a well defined mean

\item GDP growth does!
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Unconditional mean in practice}}

\begin{itemize}
\item The unconditional mean is an interesting element of VAR\ analysis but
it is often ignored\medskip \pause

\item From the estimated VAR, recover both $\mathbf{c}$ and $\mathbf{F}$%
\medskip

\item Compute the unconditional mean as 
\begin{equation*}
{\small 
\begin{array}{c}
\mathbf{(I-\mathbf{F})}^{-1}\mathbf{c}=\left[ 
\begin{array}{ccc}
2.32 & -0.28 & -1.89 \\ 
1.34 & 1.24 & 10.58 \\ 
4.89 & 0.67 & 33.87%
\end{array}%
\right] \left[ 
\begin{array}{c}
1.14 \\ 
1.19 \\ 
-0.11%
\end{array}%
\right] =\left[ 
\begin{array}{c}
2.51 \\ 
1.80 \\ 
2.49%
\end{array}%
\right] =\left[ 
\begin{array}{l}
\mu ^{\Delta y} \\ 
\mu ^{\pi } \\ 
\mu ^{i}%
\end{array}%
\right]%
\end{array}%
}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Why stationarity of the data is important}}

\begin{itemize}
\item In absence of shocks, {{\color{red} each variable will converge to its
unconditional mean}}\bigskip
\end{itemize}

\begin{minipage}{.25\textwidth}
For example, start from a point in time $T$ where:\\

\vspace{.05cm}

$y_{T}=2\%$ \\
$\pi_{T} =2\%$  \\
$r_{T}=4\%$
\end{minipage}\ \ \ \ \ \ \ 
\begin{minipage}{.65\textwidth}
\begin{figure}[h]
\begin{flushleft}
\includegraphics[width=.99\textwidth]{uncond_mean.pdf}
\end{flushleft}
\end{figure}
\end{minipage}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{In light of these considerations: is our data sensible?}}

\begin{itemize}
\item UK\ quarterly data from 1985.I to 2013.III\medskip\ 
\begin{figure}[h]
\centering
\includegraphics[width=.30\textwidth]{X1.pdf} \includegraphics[width=.30%
\textwidth]{X2.pdf} \includegraphics[width=.30\textwidth]{X3.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Some VAR\ limitations}}

\begin{itemize}
\item VARs are {{\color{red} linear}} models of {{\color{red} stationary data%
}}\bigskip 

\item ... but often macro data

\begin{itemize}
\item is non-linear (crisis periods)

\item is non-stationary (trends, breaks, etc)

\item displays time-varying variance (Great Moderation Vs Great
Recession)\bigskip \pause
\end{itemize}

\item All these elements have to be taken into account when analyzing the
output from VAR\ analysis (especially when estimated over the sample period
we use these days which features all the above)
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Back to our estimated VAR}} 
\begin{table}[tbph]
{\footnotesize \centering%
\begin{tabular}{lrrr}
\addlinespace\toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule c & 1.14 & 1.19 & -0.11 \\ 
Real GDP(-1) & 0.61 & -0.07 & 0.06 \\ 
GDP Deflator(-1) & -0.09 & 0.02 & 0.03 \\ 
Policy Rate(-1) & 0.01 & 0.30 & 0.96 \\ 
\bottomrule &  &  & 
\end{tabular}%
}
\end{table}

\begin{itemize}
\item What can we do with it?\smallskip

\begin{itemize}
\item What are the dynamic properties of these variables? [{{\color{red}
Look at lagged coefficients}}]\smallskip \pause

\item How do these variables interact? [{{\color{red} Look at cross-variable
coefficients}}]\smallskip \pause

\item What will be inflation tomorrow? [{{\color{red} ???}}]
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Forecasting}}

\begin{itemize}
\item Forecasting is one of the main objectives of multivariate time series
analysis\medskip \pause

\item The best linear predictor (in terms of minimum mean squared error) of $%
\mathbf{x}_{T+1}$ based on information available at time $T$ (today) is%
\begin{equation*}
\mathbf{x}_{T+1}^{\mathbf{f}}=\mathbf{Fx}_{T}
\end{equation*}%
\pause

\item For example, if today ($T$) we have 
\begin{equation*}
{\small 
\begin{array}{c}
\mathbf{x}_{T}\left[ 
\begin{array}{l}
\Delta y_{T}=2\% \\ 
\pi _{T}=2\% \\ 
r_{T}=4\%%
\end{array}%
\right] \ \ \ \ \ \Longrightarrow \ \ \ \ \ \mathbf{x}_{T+1}^{\mathbf{f}}=%
\mathbf{Fx}_{T}\left[ 
\begin{array}{l}
\Delta y_{T+1}=2.15\% \\ 
\pi _{T+1}=2.31\% \\ 
r_{T+1}=3.94\%%
\end{array}%
\right] 
\end{array}%
}
\end{equation*}

\item Note that we can also construct conditional forecasts by specifying an
exogenous path for a variable (the policy rate for example)
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- The identification problem}

\begin{frame}
%TCIMACRO{\TeXButton{section}{\color{title} \centering \Large}}%
%BeginExpansion
\color{title} \centering \Large%
%EndExpansion
\textbf{The Identification Problem}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Back to our estimated VAR}} 
\begin{table}[tbph]
{\footnotesize \centering%
\begin{tabular}{lrrr}
\addlinespace\toprule & Real GDP & GDP Deflator & Policy Rate \\ 
\midrule c & 1.14 & 1.19 & -0.11 \\ 
Real GDP(-1) & 0.61 & -0.07 & 0.06 \\ 
GDP Deflator(-1) & -0.09 & 0.02 & 0.03 \\ 
Policy Rate(-1) & 0.01 & 0.30 & 0.96 \\ 
\bottomrule &  &  & 
\end{tabular}%
}
\end{table}

\begin{itemize}
\item What can we do with it?\smallskip

\begin{itemize}
\item What are the dynamic properties of these variables? [{{\color{red}
Look at lagged coefficients}}]\smallskip \pause

\item How do these variables interact? [{{\color{red} Look at cross-variable
coefficients}}]\smallskip \pause

\item What will be inflation tomorrow [{{\color{red} Forecasting}}%
]\smallskip \pause

\item What is the effect of a monetary policy shock on GDP and inflation? [{{%
\color{red} ???}}]
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Reduced-form VARs do not tell us anything about the structure of
the economy}}

\begin{itemize}
\item We cannot interpret the reduced-form error terms ($\mathbf{u}$) as {%
structural shocks}\smallskip \pause

\begin{itemize}
\item How do we interpret a movement in $u_{r}$? Since it is a linear
combination of $\varepsilon _{r}$, $\varepsilon _{\Delta y}$, and $%
\varepsilon _{\pi }$ it is hard to know what is the nature of the
shock\bigskip \pause
\end{itemize}

\item Is it a shock to aggregate demand that induces policy to move the
interest rate?\ Or is it a monetary policy shock?

\begin{itemize}
\item This is the very nature of the {{\color{red} identification problem}}%
\bigskip \pause
\end{itemize}

\item To answer this question we need to get back to the structural
representation (where the error terms are uncorrelated)
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{From the reduced-form back to the structural form}}

\begin{itemize}
\item We normally estimate%
\begin{equation*}
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+{\mathbf{u}_{t}}\ \ \ \ \ \text{and}\ \ \ \
\ \Sigma _{\mathbf{u}}
\end{equation*}%
\pause

\item But our ultimate objective is to recover 
\begin{equation*}
\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+{\mathbf{\varepsilon }_{t}}
\end{equation*}%
\pause

\item Does not sound too difficult...\ We know that%
\begin{equation*}
\begin{array}{l}
\mathbf{F}=\mathbf{A}^{-1}\mathbf{B} \\ 
\mathbf{u}_{t}=\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}%
\end{array}%
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item We also know that 
\begin{equation*}
\Sigma _{\mathbf{u}}=\mathsf{E}\left[ \mathbf{u}_{t}\mathbf{u}_{t}^{\prime }%
\right] =\mathsf{E}\left[ \mathbf{A}^{-1}\mathbf{\varepsilon }\left( \mathbf{%
A}^{-1}\mathbf{\varepsilon }\right) ^{\prime }\right] =\mathbf{A}^{-1}\Sigma
_{\mathbf{\varepsilon }}\left( \mathbf{A}^{-1}\right) ^{\prime }=\mathbf{A}%
^{-1}\mathbf{A}^{-1\prime }
\end{equation*}%
since $\Sigma _{\mathbf{\varepsilon }}=\mathbf{I}\medskip $\pause

\item In other words if we pin down $\mathbf{A}^{-1}$ we are done, since we
can recover

\begin{itemize}
\item $\mathbf{\varepsilon }_{t}=\mathbf{Au}_{t}$

\item $\mathbf{B=AF}$
\end{itemize}

and we would know the structural representation of the economy$\medskip $%
\pause

\item You can think of the idnetified $\mathbf{Ax}_{t}=\mathbf{Bx}_{t-1}+{%
\mathbf{\varepsilon }_{t}}$ model as the 3 equation New Keynesian model
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {The
variance--covariance matrix of residuals} }}

\begin{itemize}
\item Why $\Sigma _{\mathbf{u}}=\mathsf{E}\left[ \mathbf{u}_{t}\mathbf{u}%
_{t}^{\prime }\right] ?\medskip $

\item The formula for the variance of a univariate time series is $%
x=[x_{0},x_{1},...,x_{T}]$%
\begin{equation*}
\mathsf{VAR}=\sum_{t=0}^{T}\frac{\left( x_{t}-\bar{x}\right) ^{2}}{N}
\end{equation*}

\item But the residuals (both the $\mathbf{u}_{t}$ and the $\mathbf{%
\varepsilon }_{t}$) have zero mean which implies that formula would be 
\begin{equation*}
\mathsf{VAR}=\sum_{t=0}^{T}\frac{x_{t}^{2}}{N}
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {The
variance--covariance matrix of residuals} }}

\begin{itemize}
\item In a bivariate VAR\ we would have 
\begin{equation*}
\mathbf{u}_{t}\mathbf{u}_{t}^{\prime }=\left[ 
\begin{array}{cccc}
{\footnotesize u}_{1}^{1} & {\footnotesize u}_{2}^{1} & {\footnotesize ...}
& {\footnotesize u}_{T}^{1} \\ 
{\footnotesize u}_{1}^{2} & {\footnotesize u}_{2}^{2} & {\footnotesize ...}
& {\footnotesize u}_{T}^{2}%
\end{array}%
\right] \left[ 
\begin{array}{cc}
{\footnotesize u}_{1}^{1} & {\footnotesize u}_{1}^{2} \\ 
{\footnotesize u}_{2}^{1} & {\footnotesize u}_{2}^{2} \\ 
{\footnotesize ...} & {\footnotesize ...} \\ 
{\footnotesize u}_{T}^{1} & {\footnotesize u}_{T}^{2}%
\end{array}%
\right] =\left[ 
\begin{array}{cc}
\sum_{t=0}^{T}\left( u_{t}^{1}\right) ^{2} & \sum_{t=0}^{T}\left(
u_{t}^{1}u_{t}^{2}\right) \\ 
- & \sum_{t=0}^{T}\left( u_{t}^{2}\right) ^{2}%
\end{array}%
\right]
\end{equation*}

\item And therefore 
\begin{equation*}
\mathsf{E}\left[ \mathbf{u}_{t}\mathbf{u}_{t}^{\prime }\right] =\left[ 
\begin{array}{cc}
\mathsf{VAR}\left[ u^{1}\right] & \mathsf{COV}\left[ u^{1}u^{2}\right] \\ 
- & \mathsf{VAR}\left[ u^{1}\right]%
\end{array}%
\right]
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
{\textbf{The \textquotedblleft identification problem\textquotedblright }}

\begin{itemize}
\item Identification problem boils down to pinning down $\mathbf{A}^{-1}$%
\medskip \pause

\item If we write $\Sigma _{\mathbf{u}}=\mathbf{A}^{-1}\mathbf{A}^{-1\prime }
$ in matrices%
\begin{equation*}
\underset{\left[ 
\begin{array}{ccc}
\sigma _{u1}^{2} & \sigma _{u1,u2}^{2} & \sigma _{u1,u3}^{2} \\ 
- & \sigma _{u2}^{2} & \sigma _{u2,u3}^{2} \\ 
- & - & \sigma _{u3}^{2}%
\end{array}%
\right] }{\underbrace{\Sigma _{\mathbf{u}}}}=\underset{\left[ 
\begin{array}{ccc}
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\ 
a_{31} & a_{32} & a_{33}%
\end{array}%
\right] ^{-1}\left[ 
\begin{array}{ccc}
a_{11} & a_{12} & a_{13} \\ 
a_{21} & a_{22} & a_{23} \\ 
a_{31} & a_{32} & a_{33}%
\end{array}%
\right] ^{-1\prime }}{\underbrace{\mathbf{A}^{-1}\mathbf{A}^{-1\prime }}}
\end{equation*}%
we can derive a system of equations\medskip \pause

\item However, there are 9 unknowns (the elements of $\mathbf{A}^{-1}\mathbf{%
A}^{-1\prime }$) but only 6 equations (because the variance-covariance
matrix is symmetric)

\begin{itemize}
\item {{\color{red} The system is not identified!}}
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- Common identification schemes}

\begin{frame}
%TCIMACRO{\TeXButton{section}{\color{title} \centering \Large}}%
%BeginExpansion
\color{title} \centering \Large%
%EndExpansion
\textbf{Common Identification Schemes}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Common identification schemes}}

\begin{itemize}
\item Zero short-run restrictions (also known as recursive, Cholesky,
orthogonal)\medskip

\item Zero long-run restrictions (also known as Blanchard-Quah)\medskip

\item Theory-based restrictions\medskip

\item Sign restrictions
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- Common identification schemes: zero short-run restrictions}

\begin{frame}
{\textbf{Zero short-run restrictions}}

\begin{itemize}
\item Assume that A is lower triangular 
\begin{equation*}
\left[ 
\begin{array}{ccc}
a_{11} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
a_{21} & a_{22} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
a_{31} & a_{32} & a_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t} \\ 
\pi _{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
b_{11} & b_{12} & b_{13} \\ 
b_{21} & b_{22} & b_{23} \\ 
b_{31} & b_{32} & b_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t-1} \\ 
\pi _{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+%
\begin{bmatrix}
\varepsilon _{\Delta yt} \\ 
\varepsilon _{\pi t} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
\end{equation*}%
\pause

\item Or in other words that

\begin{itemize}
\item $\varepsilon _{\Delta yt}$ affects contemporaneously all variables,
namely $\Delta y_{t}$, $\pi _{t}$ and $r_{t}$

\item $\varepsilon _{\pi t}$ affects contemporaneously only $\pi _{t}$ and $%
r_{t}$, but no $\Delta y_{t}$

\item $\varepsilon _{rt}$ affects contemporaneously only $r_{t}$\smallskip 
\pause
\end{itemize}

\item We now have 6 unknowns and 6 equations!
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item To see what are the implications of our assumptions on $\mathbf{A}$,
first remember that the inverse of a lower triangular matrix is also lower
triangular%
\begin{equation*}
{\small \left[ 
\begin{array}{ccc}
a_{11} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
a_{21} & a_{22} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
a_{31} & a_{32} & a_{33}%
\end{array}%
\right] ^{-1}=\left[ 
\begin{array}{ccc}
\tilde{a}_{11} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
\tilde{a}_{21} & \tilde{a}_{22} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
\tilde{a}_{31} & \tilde{a}_{32} & \tilde{a}_{33}%
\end{array}%
\right]}
\end{equation*}

\item Now pre-multiply the VAR\ by $\mathbf{A}^{-1}$%
\begin{equation*}
{\small 
\begin{bmatrix}
\Delta y_{t} \\ 
\pi _{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
f_{11} & f_{12} & f_{13} \\ 
f_{21} & f_{22} & f_{23} \\ 
f_{31} & f_{32} & f_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\Delta y_{t-1} \\ 
\pi _{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+\left[ 
\begin{array}{ccc}
\tilde{a}_{11} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
\tilde{a}_{21} & \tilde{a}_{22} & {%
%TCIMACRO{\TeXButton{note}{\color{red}}}%
%BeginExpansion
\color{red}%
%EndExpansion
{0}} \\ 
\tilde{a}_{31} & \tilde{a}_{32} & \tilde{a}_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\varepsilon _{\Delta yt} \\ 
\varepsilon _{\pi t} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
}
\end{equation*}

\item Which implies that 
\begin{equation*}
{\small \left\{ 
\begin{array}{ll}
\Delta y_{t} & =...+\tilde{a}_{11}\varepsilon _{\Delta yt}\smallskip \\ 
\pi _{t} & =...+\tilde{a}_{21}\varepsilon _{\Delta yt}+\tilde{a}%
_{22}\varepsilon _{\pi t}\smallskip \\ 
r_{t} & =...+\tilde{a}_{31}\varepsilon _{\Delta yt}+\tilde{a}%
_{32}\varepsilon _{\pi t}+\tilde{a}_{33}\varepsilon _{rt}%
\end{array}%
\right.}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item We normally implement this identification scheme \emph{via} a {{%
\color{red} Cholesky decomposition}} of $\Sigma _{\mathbf{u}}$%
\begin{equation*}
\Sigma _{\mathbf{u}}=\mathbf{P}^{\prime }\mathbf{P}
\end{equation*}%
where $\mathbf{P}^{\prime }$ is lower triangular\bigskip \pause

\item Note that%
\begin{equation*}
\Sigma _{\mathbf{u}}=\mathbf{P}^{\prime }\mathbf{P}\text{ \ \ \ \ but also \
\ \ \ }\Sigma _{\mathbf{u}}=\mathbf{A}^{-1}\mathbf{A}^{-1\prime }
\end{equation*}

\item and that%
\begin{equation*}
\mathbf{A}\text{ is lower triangular}
\end{equation*}%
\pause

\item Then it musty follow that $\mathbf{P}^{\prime }\mathbf{=A}%
^{-1}\Longrightarrow $ Identification!
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ {Cholesky decomposition
of a matrix } }}

\begin{itemize}
\item Don't be scared of Cholesky decomposition! It's a kind of square root
of a matrix

\begin{itemize}
\item As in Excel you type \texttt{sqrt()} in Matlab you type \texttt{chol()}%
\medskip \pause
\end{itemize}

\item A symmetric and positive definite matrix $\mathbf{X}$ can be
decomposed as:%
\begin{equation*}
\mathbf{X}=\mathbf{P}^{\prime }\mathbf{P}
\end{equation*}%
where $\mathbf{P}$ is an upper triangular matrix (and therefore $\mathbf{P}%
^{\prime }$ is lower triangular)\medskip \pause

\item The formula is 
\begin{equation*}
\mathbf{X}=%
\begin{bmatrix}
a & b \\ 
b & c%
\end{bmatrix}%
\ \ \ \mathbf{P}=%
\begin{bmatrix}
\sqrt{a} & \frac{b}{\sqrt{a}} \\ 
0 & \sqrt{c-\frac{b^{2}}{a}}%
\end{bmatrix}%
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\section{ -- Common identification schemes: zero long-run restrictions}

\begin{frame}
{\textbf{Zero long-run restrictions}}

\begin{itemize}
\item Re-write the VAR as%
\begin{equation*}
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}
\end{equation*}%
\pause

\item If a shock hits in $t$, its cumulative (long run) impact on $\mathbf{x}%
_{t}$ would be%
\begin{equation*}
\mathbf{x}_{t,t+\infty }=\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}\mathbf{+FA}%
^{-1}\mathbf{\varepsilon }_{t}\mathbf{+F}^{2}\mathbf{A}^{-1}\mathbf{%
\varepsilon }_{t}+...+\mathbf{F}^{\infty }\mathbf{A}^{-1}\mathbf{\varepsilon 
}_{t}
\end{equation*}%
\pause\smallskip

\item We can rewrite%
\begin{equation*}
\mathbf{x}_{t,t+\infty }=\sum\limits_{j=0}^{\infty }\mathbf{F}^{j}\mathbf{A}%
^{-1}\mathbf{\varepsilon }_{t}=\left( \mathbf{I}-\mathbf{F}\right) ^{-1}%
\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}=\mathbf{D\varepsilon }_{t}
\end{equation*}%
where $\mathbf{D}$ is the cumulative effect of the shock $\mathbf{%
\varepsilon }_{t}$ from time $t$ to $\infty $
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
\begin{itemize}
\item What is the intuition for $\mathbf{D}$?%
\begin{equation*}
\begin{bmatrix}
\Delta y_{t,t+\infty } \\ 
\pi _{t,t+\infty } \\ 
i_{t,t+\infty }%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
d_{11} & d_{12} & d_{13} \\ 
d_{21} & d_{22} & d_{23} \\ 
d_{31} & d_{32} & d_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\varepsilon _{yt} \\ 
\varepsilon _{\pi t} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
\end{equation*}%
\pause

\item Take the first equation: $\Delta y_{t,t+\infty }=d_{11}\varepsilon
_{yt}+d_{12}\varepsilon _{\pi t}+d_{13}\varepsilon _{rt}$

\begin{itemize}
\item $d_{13}$ represents the cumulative {impact of a monetary policy shock
(hitting in }${t}${) on the level GDP} in the long-run

\item If you believe in the neutrality of money you would expect $d_{13}=0$
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
\begin{itemize}
\item To achieve identification note that%
\begin{equation*}
\mathbf{DD}^{\prime }=\left( \mathbf{I}-\mathbf{F}\right) ^{-1}\mathbf{A}%
^{-1}\mathbf{A}^{-1\prime }\left( \mathbf{I}-\mathbf{F}\right) ^{-1\prime
}=\left( \mathbf{I}-\mathbf{F}\right) ^{-1}\Sigma _{\mathbf{u}}\left( 
\mathbf{I}-\mathbf{F}\right) ^{-1\prime }
\end{equation*}%
\pause

\item Note also that

\begin{itemize}
\item The right-hand side of the above equation is known

\item Both $\mathbf{DD}^{\prime }$ and $\left( \mathbf{I}-\mathbf{F}\right)
^{-1}\Sigma _{\mathbf{u}}\left( \mathbf{I}-\mathbf{F}\right) ^{-1\prime }$
are symmetric matrices

\item There exists an upper triangular matrix $\mathbf{P}$ such that $%
\mathbf{P}^{\prime }\mathbf{P=}\left( \mathbf{I}-\mathbf{F}\right)
^{-1}\Sigma _{\mathbf{u}}\left( \mathbf{I}-\mathbf{F}\right) ^{-1\prime }$%
\medskip \pause
\end{itemize}

\item Therefore, if we assume that $\mathbf{D}$ is lower triangular, it must
be that $\mathbf{D=P}^{\prime }$\medskip \pause

\item Finally $\mathbf{A}^{-1}=\left( \mathbf{I}-\mathbf{F}\right) \mathbf{D}%
\Longrightarrow $ Identification!
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- Common identification schemes: sign restrictions}

\begin{frame}
{\textbf{Sign restrictions}}

\begin{itemize}
\item In the zero short-run restriction identification we used the fact that%
\begin{equation*}
\Sigma _{\mathbf{u}}=\mathbf{A}^{-1}\mathbf{A}^{-1\prime }\ \ \ \text{and}\
\ \ \Sigma _{\mathbf{u}}=\mathbf{P}^{\prime }\mathbf{P}
\end{equation*}%
where the lower triangular $\mathbf{P}^{\prime }$ matrix is the Cholesky
decomposition of $\Sigma _{\mathbf{u}}$\smallskip \pause

\item For a given random {%
%TCIMACRO{\TeXButton{note text}{{\color{red} orthonormal matrix}}}%
%BeginExpansion
{\color{red} orthonormal matrix}%
%EndExpansion
} (i.e., such that $\mathbf{S}^{\prime }\mathbf{S}=\mathbf{I}$) we have that%
\begin{equation*}
\Sigma _{\mathbf{u}}=\mathbf{A}^{-1}\mathbf{A}^{-1\prime }=\mathbf{P}%
^{\prime }\mathbf{S}^{\prime }\mathbf{SP=}\mathcal{P}^{\prime }\mathcal{P}
\end{equation*}%
where $\mathcal{P}^{\prime }$ is generally not lower triangular anymore
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
\begin{itemize}
\item $\mathbf{A}^{-1}=\mathcal{P}^{\prime }$ is clearly a valid solution to
the identification problem\medskip \pause

\item But $\mathbf{S}^{\prime }$ is a random matrix... is the solution $%
\mathbf{A}^{-1}=\mathcal{P}^{\prime }$ plausible?\medskip \pause

\item Identification is achieved by checking whether the impulse responses
implied by $\mathbf{S}^{\prime }$ satisfy a set of a priori (and possibly
theory-driven) sign restrictions\medskip \pause

\item We can draw as many $\mathbf{S}^{\prime }$ as we want and construct a
distribution of the solutions that satisfy the sign restrictions
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Sign restriction in steps}}

\begin{enumerate}
\item Draw a random orthonormal matrix $\mathbf{S}^{\prime }$\medskip 
\pause

\item Compute $\mathbf{A}^{-1}=\mathbf{P}^{\prime }\mathbf{S}^{\prime }$
where $\mathbf{P}^{\prime }$ is the Cholesky decomposition of the reduced
form residuals $\Sigma _{\mathbf{u}}$\medskip \pause

\item Compute the impulse response associated with $\mathbf{A}^{-1}$\medskip 
\pause

\item Are the sign restrictions satisfied?

\begin{enumerate}
\item Yes. Store the impulse response

\item No. Discard the impulse response\medskip \pause
\end{enumerate}

\item Perform $N\ $replications and report the median impulse response (and
its confidence intervals)
\end{enumerate}
\end{frame}

\vspace{.1cm}

\section{ -- Structural Dynamic Analysis}

\begin{frame}
%TCIMACRO{\TeXButton{section}{\color{title} \centering \Large}}%
%BeginExpansion
\color{title} \centering \Large%
%EndExpansion
\textbf{Structural Dynamic Analysis}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Why do we need identification?}}

\begin{itemize}
\item According to Stock \&\ Watson's list so far we have done

\begin{enumerate}
\item Describe and summarize macroeconomic time series

\item Make forecasts

\item Recover the true structure of the macroeconomy from the data\medskip 
\pause
\end{enumerate}

\item How about

\begin{enumerate}
\item Advise macroeconomic policymakers\medskip \pause
\end{enumerate}

\item (A good) identification allows us to address the last point\medskip 
\pause

\item This is normally done by means of {{\color{red} Impulse responses}}, {{%
\color{red} Forecast error variance decompositions}}, and {{\color{red}
Historical decompositions}}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Impulse response functions}}

\begin{itemize}
\item Impulse response functions ($\mathcal{IR}$) answer the question

\begin{itemize}
\item What is the response of current and future values of each of the
variables to a one-unit increase in the current value of one of the
structural errors, assuming that this error returns to zero in subsequent
periods and that all other errors are equal to zero\medskip \pause
\end{itemize}

\item The implied thought experiment of changing one error while holding the
others constant makes sense only when the errors are uncorrelated across
equations
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{How to compute {impulse response functions}}}

\begin{itemize}
\item As an example, we compute the $\mathcal{IR}$ for a bivariate VAR $%
\mathbf{x}_{t}=\left( x_{1t}^{\prime },x_{2t}^{\prime }\right) $ \medskip 
\pause

\item Define a vector of exogenous impulses\ ($\mathbf{s}_{\tau }$) that we
want to to impose to the structural errors of the system%
\begin{equation*}
{\small 
\begin{tabular}{lllll}
\hline
$\text{Time (}\tau \text{)}$ &  & $1$ & $2$ & $h$ \\ \hline
$\text{Impulse to }\varepsilon _{1}\text{ (}s_{1,\tau }\text{)}$ &  & $%
s_{1,1}=1$ & $s_{1,2}=0$ & $s_{1,h}=0$ \\ 
$\text{Impulse to }\varepsilon _{2}\text{ (}s_{2,\tau }\text{)}$ &  & $%
s_{2,1}=0$ & $s_{2,2}=0$ & $s_{2,h}=0$ \\ \hline
\end{tabular}%
}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item We can use the following hybrid representation to compute the $%
\mathcal{IR}$%
\begin{equation*}
\mathbf{x}_{t}=\mathbf{Fx}_{t-1}+\mathbf{A}^{-1}\mathbf{s}_{t},
\end{equation*}%
\pause

\item The impulse response $\mathcal{IR}_{\tau }$ is given by%
\begin{equation*}
\left\{ 
\begin{array}{l}
\mathcal{IR}_{1}=\mathbf{A}^{-1}\mathbf{s}_{1}, \\ 
\mathcal{IR}_{\tau }=\mathbf{F\cdot }\mathcal{IR}_{\tau -1},\text{ \ \ \ \
for }\tau =2,...,h.%
\end{array}%
\right.
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{Forecast error variance decompositions}}

\begin{itemize}
\item Forecast error variance decompositions\ ($\mathcal{VD}$) answer the
question

\begin{itemize}
\item What portion of the {{variance of the forecast error in predicting $%
x_{i,T+h}$ is due to the structural shock $\varepsilon _{i}$}}? \medskip %
\pause
\end{itemize}

\item Provide information about the relative importance of each structural
shock in affecting the variables in the VAR
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{How to compute {forecast error variance decompositions}}}

\begin{itemize}
\item As an example, we compute the $\mathcal{VD}$ for the 1-step ahead
forecast error in a bivariate VAR $\mathbf{x}_{t}=\left( x_{1t}^{\prime
},x_{2t}^{\prime }\right) $\medskip \pause

\item First, let's define the 1-step ahead forecast error%
\begin{equation*}
\mathbf{\xi }_{T+1}=\mathbf{x}_{T+1}-\mathbf{x}_{T+1}^{\mathbf{f}}=\mathbf{x}%
_{T+1}-\mathbf{Fx}_{T}
\end{equation*}

\item It follows that%
\begin{equation*}
\mathbf{\xi }_{T+1}=\underset{%
\begin{array}{c}
\text{{\footnotesize Forecast error is the yet unobserved }} \\ 
\text{{\footnotesize realization of the shocks}}%
\end{array}%
}{\mathbf{u}_{T+1}\ \ \ \ \ \ =\ \ \ \ \ \ \mathbf{A}^{-1}\mathbf{%
\varepsilon }_{T+1}}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item In a bivariate VAR we have%
\begin{equation*}
{\small \left[ 
\begin{array}{c}
\mathbf{\xi }_{1,T+1} \\ 
\mathbf{\xi }_{2,T+1}%
\end{array}%
\right] =%
\begin{bmatrix}
\tilde{a}_{11} & \tilde{a}_{12} \\ 
\tilde{a}_{21} & \tilde{a}_{22}%
\end{bmatrix}%
\begin{bmatrix}
\varepsilon _{1,T+1} \\ 
\varepsilon _{2,T+1}%
\end{bmatrix}%
}
\end{equation*}%
where $\tilde{a}$ are the elements of $\mathbf{A}^{-1}$

\item Or%
\begin{equation*}
{\small \left\{ 
\begin{array}{l}
\mathbf{\xi }_{1,T+1}=\tilde{a}_{11}\varepsilon _{1,T+1}+\tilde{a}%
_{12}\varepsilon _{2,T+1}\medskip \\ 
\mathbf{\xi }_{2,T+1}=\tilde{a}_{21}\varepsilon _{1,T+1}+\tilde{a}%
_{22}\varepsilon _{2,T+1}%
\end{array}%
\right. }
\end{equation*}

\item What is the variance of the forecast error?%
\begin{equation*}
{\small 
\begin{array}{c}
\mathsf{VAR}\left( \mathbf{\xi }_{1,T+1}\right) =\tilde{a}_{11}^{2}\mathsf{%
VAR}\left( \varepsilon _{1,T+1}\right) +\tilde{a}_{12}^{2}\mathsf{VAR}\left(
\varepsilon _{2,T+1}\right) =\tilde{a}_{11}^{2}+\tilde{a}_{12}^{2}\medskip
\\ 
\mathsf{VAR}\left( \mathbf{\xi }_{2,T+1}\right) =\tilde{a}_{21}^{2}\mathsf{%
VAR}\left( \varepsilon _{1,T+1}\right) +\tilde{a}_{22}^{2}\mathsf{VAR}\left(
\varepsilon _{2,T+1}\right) =\tilde{a}_{21}^{2}+\tilde{a}_{22}^{2}%
\end{array}%
}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ Basic properties of the
variance }}

\begin{itemize}
\item If X is a random variable $\mathbf{X}$ and $a$ is a constant

\begin{itemize}
\item $\mathsf{VAR}\left( \mathbf{X}+a\right) =\mathsf{VAR}\left( \mathbf{X}%
\right) $

\item $\mathsf{VAR}\left( a\mathbf{X}\right) =a^{2}\mathsf{VAR}\left( 
\mathbf{X}\right) $\medskip \pause
\end{itemize}

\item If $\mathbf{Y}$ is a random variable and $b$ is a constant

\begin{itemize}
\item $\mathsf{VAR}\left( a\mathbf{X+}b\mathbf{Y}\right) =a^{2}\mathsf{VAR}%
\left( \mathbf{X}\right) +b^{2}\mathsf{VAR}\left( \mathbf{Y}\right) +2ab%
\mathsf{COV}\left( \mathbf{X},\mathbf{Y}\right) $\medskip \pause
\end{itemize}

\item Since the structural errors are independent, it follows that $\mathsf{%
COV}\left( \varepsilon _{1},\varepsilon _{2}\right) =0$
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item Therefore, we just showed that variance of the 1-step ahead forecast
error is 
\begin{equation*}
\begin{array}{c}
\mathsf{VAR}\left( \mathbf{\xi }_{1,T+1}\right) =\tilde{a}_{11}^{2}+\tilde{a}%
_{12}^{2}\medskip \\ 
\mathsf{VAR}\left( \mathbf{\xi }_{2,T+1}\right) =\tilde{a}_{21}^{2}+\tilde{a}%
_{22}^{2}%
\end{array}%
\end{equation*}

\item Which portion of the variance is due to each structural error?%
\begin{equation*}
\underset{\text{This sums up to 1}}{\underbrace{\left\{ 
\begin{array}{c}
\mathcal{VD}_{x_{1}}^{\varepsilon _{1}}=\frac{\tilde{a}_{11}^{2}}{\tilde{a}%
_{11}^{2}+\tilde{a}_{12}^{2}}\medskip \\ 
\mathcal{VD}_{x_{1}}^{\varepsilon _{2}}=\frac{\tilde{a}_{12}^{2}}{\tilde{a}%
_{11}^{2}+\tilde{a}_{12}^{2}}\medskip%
\end{array}%
\right. }}\ \ \ \ \ \ \underset{\text{This sums up to 1}}{\underbrace{%
\left\{ 
\begin{array}{c}
\mathcal{VD}_{x_{2}}^{\varepsilon _{1}}=\frac{\tilde{a}_{21}^{2}}{\tilde{a}%
_{21}^{2}+\tilde{a}_{22}^{2}}\medskip \\ 
\mathcal{VD}_{x_{2}}^{\varepsilon _{2}}=\frac{\tilde{a}_{22}^{2}}{\tilde{a}%
_{21}^{2}+\tilde{a}_{22}^{2}}\medskip%
\end{array}%
\right. }}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Historical decompositions}}

\begin{itemize}
\item Historical decompositions ($\mathcal{HD}$) answer the question

\begin{itemize}
\item What portion of the {{deviation {of $x_{i,t}$ }from its unconditional
mean is due to the structural shock $\varepsilon _{i}$}}?\medskip \pause
\end{itemize}

\item We showed before that each observation of a variable does not
generally coincide with its unconditional mean\medskip

\item This is because, in each period, the structural shocks realize and
push all variables away from their equilibrium values
\end{itemize}
\end{frame}

\vspace{0.1cm}

%TCIMACRO{%
%\TeXButton{B2B}{\setbeamercolor{frametitle}{fg=note!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
%\setbeamercolor{itemize item}{fg=note!80}
%\setbeamercolor{itemize subitem}{fg=note!80}
%\setbeamercolor{itemize subsubitem}{fg=note!80}
%\setbeamercolor{enumerate item}{fg=note!80}
%\setbeamercolor{enumerate subitem}{fg=note!80}
%\everymath\expandafter{\the\everymath \color{note!80}}
%\everydisplay\expandafter{\the\everydisplay \color{note!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=note!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{note in head/foot}{fg=note!95,bg=note!95}
\setbeamercolor{itemize item}{fg=note!80}
\setbeamercolor{itemize subitem}{fg=note!80}
\setbeamercolor{itemize subsubitem}{fg=note!80}
\setbeamercolor{enumerate item}{fg=note!80}
\setbeamercolor{enumerate subitem}{fg=note!80}
\everymath\expandafter{\the\everymath \color{note!80}}
\everydisplay\expandafter{\the\everydisplay \color{note!80}}%
%EndExpansion

\begin{frame}
{{\footnotesize \textbf{[Back to basics]}} \textbf{\ Wold representation of
a VAR}}

\begin{itemize}
\item Each observation of our original data can be re-written as the
cumulative sum of the structural shocks%
\begin{equation*}
{\small 
\begin{array}{lll}
\mathbf{x}_{2} & = & \mathbf{Fx}_{1}+\mathbf{A}^{-1}\mathbf{\varepsilon }%
_{2}\medskip \\ 
\mathbf{x}_{3} & = & \mathbf{Fx}_{2}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{3}%
\mathbf{=F(\mathbf{Fx}}_{1}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{2}\mathbf{%
)+A}^{-1}\mathbf{\varepsilon }_{3}=\mathbf{F}^{2}\mathbf{x}_{1}+\mathbf{FA}%
^{-1}\mathbf{\varepsilon }_{2}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{3} \\ 
& = & ...\ = \\ 
\mathbf{x}_{T} & = & \mathbf{F}^{T-1}\mathbf{x}_{1}+(\mathbf{F}^{T-2}\mathbf{%
A}^{-1}\mathbf{\varepsilon }_{2}+...+\mathbf{FA}^{-1}\mathbf{\varepsilon }%
_{T-1}+\mathbf{A}^{-1}\mathbf{\varepsilon }_{T})%
\end{array}%
}
\end{equation*}%
\pause

\item Or, more in general%
\begin{equation*}
\mathbf{x}_{t}=\mathbf{F}^{t-1}\mathbf{x}_{1}+\sum\limits_{j=0}^{t-2}\mathbf{%
F}^{j}\mathbf{A}^{-1}\mathbf{\varepsilon }_{t-j}\ \ \ \ \ \text{for }t>1
\end{equation*}
\end{itemize}
\end{frame}

%TCIMACRO{%
%\TeXButton{EndB2B}{\setbeamercolor{frametitle}{fg=title!95,bg=white} 
%\setbeamercolor{author in head/foot}{fg=white,bg=title}
%\setbeamercolor{title in head/foot}{fg=white,bg=title} 
%\setbeamercolor{itemize item}{fg=title!80}
%\setbeamercolor{itemize subitem}{fg=title!80}
%\setbeamercolor{itemize subsubitem}{fg=title!80}
%\setbeamercolor{enumerate item}{fg=title!80}
%\setbeamercolor{enumerate subitem}{fg=title!80}
%\everymath\expandafter{\the\everymath \color{title!80}}
%\everydisplay\expandafter{\the\everydisplay \color{title!80}}}}%
%BeginExpansion
\setbeamercolor{frametitle}{fg=title!95,bg=white} 
\setbeamercolor{author in head/foot}{fg=white,bg=title}
\setbeamercolor{title in head/foot}{fg=white,bg=title} 
\setbeamercolor{itemize item}{fg=title!80}
\setbeamercolor{itemize subitem}{fg=title!80}
\setbeamercolor{itemize subsubitem}{fg=title!80}
\setbeamercolor{enumerate item}{fg=title!80}
\setbeamercolor{enumerate subitem}{fg=title!80}
\everymath\expandafter{\the\everymath \color{title!80}}
\everydisplay\expandafter{\the\everydisplay \color{title!80}}%
%EndExpansion

\vspace{0.1cm}

\begin{frame}
{\textbf{How to compute historical decompositions }}

\begin{itemize}
\item As an example, we compute the $\mathcal{HD}$ of the third observation
in a bivariate VAR $\mathbf{x}_{t}=\left( x_{1t}^{\prime },x_{2t}^{\prime
}\right) ^{\prime }$\medskip \pause

\item First write $\mathbf{x}_{3}$ as a function of past errors ($\mathbf{%
\varepsilon }_{2}$ and $\mathbf{\varepsilon }_{3}$) and the initial
conditions ($\mathbf{x}_{1}$)%
\begin{equation*}
\mathbf{x}_{3}=\underset{init_{3}}{\underbrace{\mathbf{F}^{2}\mathbf{x}_{1}}}%
+\underset{\boldsymbol{\Theta }_{\boldsymbol{1}}}{\underbrace{\mathbf{FA}%
^{-1}}}\mathbf{\varepsilon }_{2}+\underset{\boldsymbol{\Theta }_{\boldsymbol{%
0}}}{\underbrace{\mathbf{A}^{-1}}}\mathbf{\varepsilon }_{3}
\end{equation*}%
\pause

\item Re-write $\mathbf{x}_{3}$ in matrices%
\begin{equation*}
{\small 
\begin{bmatrix}
x_{1,3} \\ 
x_{2,3}%
\end{bmatrix}%
=%
\begin{bmatrix}
init_{1,3} \\ 
init_{2,3}%
\end{bmatrix}%
+%
\begin{bmatrix}
\theta _{11}^{1} & \theta _{12}^{1} \\ 
\theta _{21}^{1} & \theta _{22}^{1}%
\end{bmatrix}%
\begin{bmatrix}
\varepsilon _{1,2} \\ 
\varepsilon _{2,2}%
\end{bmatrix}%
+%
\begin{bmatrix}
\theta _{11}^{0} & \theta _{12}^{0} \\ 
\theta _{21}^{0} & \theta _{22}^{0}%
\end{bmatrix}%
\begin{bmatrix}
\varepsilon _{1,3} \\ 
\varepsilon _{2,3}%
\end{bmatrix}%
}
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\begin{frame}
\begin{itemize}
\item Therefore $\mathbf{x}_{3}$ can be expressed as 
\begin{equation*}
{\small \left\{ 
\begin{array}{l}
\mathbf{x}_{1,3}=init_{1,3}+\theta _{11}^{1}\varepsilon _{1,2}+\theta
_{12}^{1}\varepsilon _{2,2}+\theta _{11}^{0}\varepsilon _{1,3}+\theta
_{12}^{0}\varepsilon _{2,3}\medskip \\ 
\mathbf{x}_{2,3}=init_{2,3}+\theta _{21}^{1}\varepsilon _{1,2}+\theta
_{22}^{1}\varepsilon _{2,2}+\theta _{21}^{0}\varepsilon _{1,3}+\theta
_{22}^{0}\varepsilon _{2,3}%
\end{array}%
\right. }
\end{equation*}%
\pause

\item The historical decomposition is given by 
\begin{equation*}
\begin{array}{ccc}
\underset{\text{This sums up to }\mathbf{x}_{1,3}}{\underbrace{{\small %
\left\{ 
\begin{array}{l}
\mathcal{HD}_{1,3}^{\varepsilon _{1}}=\theta _{11}^{1}\varepsilon
_{1,2}+\theta _{11}^{0}\varepsilon _{1,3}\medskip \\ 
\mathcal{HD}_{1,3}^{\varepsilon _{2}}=\theta _{12}^{1}\varepsilon
_{2,2}+\theta _{12}^{0}\varepsilon _{2,3}\medskip \\ 
\mathcal{HD}_{1,3}^{init}=init_{1,3}\medskip%
\end{array}%
\right. }}} &  & \underset{\text{This sums up to }\mathbf{x}_{2,3}}{%
\underbrace{{\small \left\{ 
\begin{array}{l}
\mathcal{HD}_{2,3}^{\varepsilon _{1}}=\theta _{21}^{1}\varepsilon
_{1,2}+\theta _{21}^{0}\varepsilon _{1,3}\medskip \\ 
\mathcal{HD}_{2,3}^{\varepsilon _{2}}=\theta _{22}^{1}\varepsilon
_{2,2}+\theta _{22}^{0}\varepsilon _{2,3}\medskip \\ 
\mathcal{HD}_{2,3}^{init}=init_{2,3}\medskip%
\end{array}%
\right. }}}%
\end{array}%
\end{equation*}
\end{itemize}
\end{frame}

\vspace{0.1cm}

\section{ -- Examples}

\begin{frame}
%TCIMACRO{\TeXButton{section}{\color{title} \centering \Large}}%
%BeginExpansion
\color{title} \centering \Large%
%EndExpansion
\textbf{\textquotedblleft Famous VAR\ Examples\textquotedblright }
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Examples of different identification schemes}}

\begin{itemize}
\item Zero short-run restrictions

\begin{itemize}
\item Stock \& Watson\ (2001). \textquotedblleft Vector
Autoregressions,\textquotedblright\ Journal of Economic Perspectives\medskip 
\pause
\end{itemize}

\item Zero long-run restrictions

\begin{itemize}
\item Blanchard \&\ Quah (1989). \textquotedblleft The Dynamic Effects of
Aggregate Demand and Supply Disturbances\textquotedblright , American
Economic Review\medskip \pause
\end{itemize}

\item Sign Restrictions

\begin{itemize}
\item Uhlig (2005). \textquotedblleft What are the effects of monetary
policy on output? Results from an agnostic identification
procedure,\textquotedblright\ Journal of Monetary Economics
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- Examples: Stock \& Watson\ (2001, JEP)}

\begin{frame}
{\textbf{Example: zero short-run restrictions}}

\begin{itemize}
\item Stock \& Watson\ (2001). \textquotedblleft Vector
Autoregressions,\textquotedblright\ Journal of Economic
Perspectives\smallskip

\item US\ quarterly data from 1960.I to 2000.IV 
\begin{figure}[h]
\centering\includegraphics[width=.30\textwidth]{SW1.pdf} %
\includegraphics[width=.30\textwidth]{SW2.pdf} \includegraphics[width=.30%
\textwidth]{SW3.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Monetary policy shocks, inflation and unemployment}}

\begin{itemize}
\item Objective: infer the causal influence of monetary policy on
unemployment, inflation and interest rates\pause

\item Assumptions

\begin{itemize}
\item MP\ ($r_{t}$) reacts contemporaneously to movements in inflation and
in unemployment

\item MP shocks ($\varepsilon _{rt}$) do not affect inflation and
unemployment within the quarter of the shock\smallskip \pause%
\begin{equation*}
\left[ 
\begin{array}{ccc}
a_{11} & {\color{red}{0}} & {\color{red}{0}} \\ 
a_{21} & a_{22} & {\color{red}{0}} \\ 
a_{31} & a_{32} & a_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\pi _{t} \\ 
ur_{t} \\ 
r_{t}%
\end{bmatrix}%
=\left[ 
\begin{array}{ccc}
b_{11} & b_{12} & b_{13} \\ 
b_{21} & b_{22} & b_{23} \\ 
b_{31} & b_{32} & b_{33}%
\end{array}%
\right] 
\begin{bmatrix}
\pi _{t-1} \\ 
ur_{t-1} \\ 
r_{t-1}%
\end{bmatrix}%
+%
\begin{bmatrix}
\varepsilon _{\pi t} \\ 
\varepsilon _{urt} \\ 
\varepsilon _{rt}%
\end{bmatrix}%
\end{equation*}
\end{itemize}

\item Do these assumptions make sense?
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{The effect of a monetary policy shock}} 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{SWirf3.pdf}
\end{figure}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{The other two shocks are identified by definition... but how can we
interpret them?}}

\begin{itemize}
\item How about $\varepsilon _{\pi }$ and $\varepsilon _{ur}$? They
represent an aggregate supply and a demand equation...

\begin{itemize}
\item The shock to $\varepsilon _{\pi }$ affects all variables
contemporaneously

\item The shock to $\varepsilon _{ur}$ affects $r_{t}$ contemporaneously but
not $\pi _{t}$\pause\bigskip
\end{itemize}

\item Do these assumptions make sense?\pause\bigskip

\item \lbrack Some shocks may be better identified than others]
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Aggregate demand and aggregate supply shocks}}

\begin{minipage}{.48\textwidth}
\begin{figure}[h]
\begin{flushleft}
\small 
\begin{itemize}
\item Shock to $\varepsilon _{\pi t}$ behaves as a negative aggregate supply shock
\end{itemize}
\vspace{.3cm}
\includegraphics[width=.99\textwidth]{SWirf1.pdf}
\end{flushleft}
\end{figure}
\end{minipage}\ \pause\ 
\begin{minipage}{.48\textwidth}
\begin{figure}[h]
\begin{flushleft}
\small 
\begin{itemize}
\item Shock to $\varepsilon _{u t}$ behaves as a negative aggregate demand shock
\end{itemize}
\vspace{.3cm}\includegraphics[width=.99\textwidth]{SWirf2.pdf}
\end{flushleft}
\end{figure}
\end{minipage}
\end{frame}

\vspace{0.1cm}

\begin{frame}
{\textbf{Forecast error variance decomposition}}

\begin{table}[tbph]
{\small \centering%
\begin{tabular}{lrrrrrrrrrrr}
\addlinespace\toprule & \multicolumn{3}{c}{Inflation} &  & 
\multicolumn{3}{c}{Unemployment} &  & \multicolumn{3}{c}{Fed Funds} \\ 
\midrule & $\varepsilon _{\pi }$ & $\varepsilon _{ur}$ & $\varepsilon _{r}$
&  & $\varepsilon _{\pi }$ & $\varepsilon _{ur}$ & $\varepsilon _{r}$ &  & $%
\varepsilon _{\pi }$ & $\varepsilon _{ur}$ & $\varepsilon _{r}$ \\ 
\cline{2-4}\cline{6-8}\cline{10-12}
t = 1 & 1.00 & 0.00 & 0.00 &  & 0.00 & 1.00 & 0.00 &  & 0.02 & 0.20 & 0.79
\\ 
t = 4 & 0.88 & 0.10 & 0.01 &  & 0.02 & 0.96 & 0.02 &  & 0.09 & 0.51 & 0.41
\\ 
t = 8 & 0.83 & 0.16 & 0.01 &  & 0.10 & 0.76 & 0.13 &  & 0.11 & 0.60 & 0.29
\\ 
t = 12 & 0.83 & 0.15 & 0.02 &  & 0.21 & 0.60 & 0.19 &  & 0.15 & 0.59 & 0.26
\\ 
\bottomrule &  &  &  &  &  &  &  &  &  &  & 
\end{tabular}%
}
\end{table}
\end{frame}

\vspace{0.1cm}

\section{ -- Examples: Blanchard \&\ Quah (1989, AER)}

\begin{frame}
{\textbf{Example: zero long-run restrictions}}

\begin{itemize}
\item Blanchard \&\ Quah (1989). \textquotedblleft The Dynamic Effects of
Aggregate Demand and Supply Disturbances\textquotedblright , American
Economic Review\smallskip

\item US\ quarterly data from 1948.I to 1987.IV 
\begin{figure}[h]
\centering\includegraphics[width=.30\textwidth]{BQ1.pdf} %
\includegraphics[width=.30\textwidth]{BQ2.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Economic theory and the long-run}}

\begin{itemize}
\item Economic theory usually tells us a lot more about what will happen in
the long-run, rather than exactly what will happen today\smallskip \pause

\begin{itemize}
\item Demand-side shocks have no long-run effect on output, while
supply-side shocks do\smallskip \pause

\item Monetary policy shocks have no long-run effect on output\smallskip 
\pause

\item ...\medskip
\end{itemize}

\item This suggests an alternative approach: to use these
theoretically-inspired long-run restrictions to identify shocks and impulse
responses
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Blanchard \&\ Quah's identification assumptions}}

\begin{itemize}
\item There are two types of disturbances affecting unemployment and
output\medskip \pause

\item The first has no long-run effect on either unemployment or output
level\medskip \pause

\item The second has no long-run effect on unemployment, but {{\color{red}
may have a long-run effect on output level}}\medskip \pause

\item Blanchard \&\ Quah refer to the first as demand disturbances, and to
the second as supply disturbances (traditional Keynesian view of
fluctuations)
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Identification}}

\begin{itemize}
\item We showed that the long-run cumulative impact of a structural shocks
is 
\begin{equation*}
\mathcal{IR}_{\tau ,\tau +\infty }=\sum\limits_{j=0}^{\infty }\mathbf{F}^{j}%
\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}=\left( \mathbf{I}-\mathbf{F}\right)
^{-1}\mathbf{A}^{-1}\mathbf{\varepsilon }_{t}=\mathbf{D\varepsilon }_{t}
\end{equation*}%
\pause

\item Assume that $\varepsilon _{t}^{\Delta y}$ is the supply shock and that 
$\varepsilon _{t}^{ur}$ is the demand shock\smallskip \pause

\item We can rewrite the VAR\ such that the cumulated effect of $\varepsilon
_{t}^{ur}$ on $\Delta y_{t}$ is equal to zero by assuming%
\begin{equation*}
\left[ 
\begin{array}{c}
\Delta y_{t} \\ 
ur_{t}%
\end{array}%
\right] =\left[ 
\begin{array}{cc}
d_{11} & {\color{red}}0 \\ 
d_{21} & d_{22}%
\end{array}%
\right] \left[ 
\begin{array}{c}
\varepsilon _{t}^{\Delta y} \\ 
\varepsilon _{t}^{ur}%
\end{array}%
\right] 
\end{equation*}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Aggregate demand and supply shocks}}

\begin{minipage}{.48\textwidth}
\begin{figure}[h]
\begin{flushleft}
\small 
\begin{itemize}
\item Aggregate supply shock initially increases unemployment 
(puzzle of hours to producticvity shocks)
\end{itemize}
\vspace{.3cm}
\includegraphics[width=.99\textwidth]{BQirf1.pdf}
\end{flushleft}
\end{figure}
\end{minipage}\ \pause\ 
\begin{minipage}{.48\textwidth}
\begin{figure}[h]
\begin{flushleft}
\small 
\begin{itemize}
\item Aggregate demand shocks have a hump-shaped effect on output and unemployment
\end{itemize}
\vspace{.3cm}\includegraphics[width=.99\textwidth]{BQirf2.pdf}
\end{flushleft}
\end{figure}
\end{minipage}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{How can we check the long-run \textquotedblleft
neutrality\textquotedblright\ of demand shocks on output level?}}

\begin{itemize}
\item Let's simply plot the cumulative sum of the impulse responses of
output growth 
\begin{figure}[h]
\centering\includegraphics[width=.60\textwidth]{BQlevel.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\section{ -- Examples: Uhlig (2005, JME)}

\begin{frame}
{\textbf{Example: sign restrictions}}

\begin{itemize}
\item Uhlig (2005). \textquotedblleft What are the effects of monetary
policy on output? Results from an agnostic identification
procedure,\textquotedblright\ Journal of Monetary Economics\smallskip

\item US\ monthly data from 1965.I to 2003.XII 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{U.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What are the effects of monetary policy on output?}}

\begin{itemize}
\item Before asking what are the effects of a monetary policy shocks we
should be asking, {{\color{red} what is a monetary policy shock?}}\medskip 
\pause

\item In the inflation targeting era a monetary policy shock is an increase
in the policy rate that

\begin{itemize}
\item is ordered last in a Cholesky decomposition?

\item has no permanent effect on output?

\item ....?
\end{itemize}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What is a monetary policy shock?}}

\begin{itemize}
\item According to conventional wisdom, monetary contractions should
\smallskip

\begin{enumerate}
\item Raise the federal funds rate\smallskip \pause

\item Lower prices\smallskip \pause

\item Decrease non-borrowed reserves\smallskip \pause

\item Reduce real output
\end{enumerate}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Again... What are the effects of monetary policy on output?}}

\begin{itemize}
\item Standard identification schemes do not fully accomplish the 4 points
above\medskip

\begin{itemize}
\item {{\color{red} Liquidity puzzle}}: when identifying monetary policy
shocks as surprise increases in the stock of money, interest rates tend to
go down, not up\smallskip \pause

\item {{\color{red} Price puzzle}}: after a contractionary monetary policy
shock, even with interest rates going up and money supply going down,
inflation goes up rather than down\bigskip \pause
\end{itemize}

\item Successful identification needs to deliver results matching the
conventional wisdom
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{Uhlig's identification assumptions}}

\begin{itemize}
\item Uhlig's assumption: a \textquotedblleft
contractionary\textquotedblright\ monetary policy shock does not lead to

\begin{itemize}
\item Increases in prices

\item Increase in nonborrowed reserves

\item Decreases in the federal funds rate\medskip \pause
\end{itemize}

\item How about output? Since is the response of interest, we leave it
un-restricted
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{[Reminder] How to compute sign restrictions}}

\begin{enumerate}
\item Estimate from the reduced-form VAR $\mathbf{F}$, ${\mathbf{u}_{t}}$,
and $\Sigma _{\mathbf{u}}$\medskip \pause

\item Draw a random orthonormal matrix $\mathbf{S}^{\prime }$, compute $%
\mathbf{P}^{\prime }=$\texttt{chol(}$\Sigma _{\mathbf{u}}$\texttt{)} and
recover $\mathbf{A}^{-1}=\mathbf{P}^{\prime }\mathbf{S}^{\prime }$\medskip 
\pause

\item Compute the impulse response using $\mathcal{IR}_{1}=\mathbf{A}^{-1}%
\mathbf{\varepsilon }_{t}$\medskip\ \pause

\item Are the sign restrictions satisfied? Yes. Store the impulse response
// No. Discard the impulse response\medskip \pause

\item Perform $N\ $replications and report the median impulse response (and
its confidence intervals)
\end{enumerate}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What happens when you do sign restrictions }}

\begin{itemize}
\item First draw: signs are correct, I keep it! 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{Usr1.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What happens when you do sign restrictions }}

\begin{itemize}
\item Second draw: signs are not correct, I discard it! 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{Usr2.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What happens when you do sign restrictions }}

\begin{itemize}
\item After a while... 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{Usr500.pdf}
\end{figure}
\end{itemize}
\end{frame}

\vspace{.1cm}

\begin{frame}
{\textbf{What are the effects of monetary policy on output?}}

\begin{itemize}
\item Ambiguous effect on real GDP $\Longrightarrow $\ Long-run monetary
neutrality 
\begin{figure}[h]
\centering\includegraphics[width=.70\textwidth]{Uirf1.pdf}
\end{figure}
\end{itemize}
\end{frame}

\end{document}
